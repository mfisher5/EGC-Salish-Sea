---
title: "classify_otherruns"
author: "M Fisher - modified from Eily Allan, Erin D'Agnese, Ramon Gallego"
date: "01/06/2022"
output:   
  html_notebook:
    toc: true
    toc_float: true
params: 
  folder:
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/classification_output/run4_20211117/MiFish
  Hash_key:
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/dada2_output/run4_20211117/MiFish/hash_key.csv
  ASVs: 
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/dada2_output/run4_20211117/MiFish/ASV_table.csv
  classifier:
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_LOCAL/Input/classifiers/classifier_12S_MiFish.rds
  previous_effort: 
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/classification_output/MiFish.all.gs.previous.hashes.annotated.rds
  local_blast: 
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/classification_output/MiFish.blast.previous.hashes.annotated.rds
  run:
    value: 4
  marker:
    value: MiFish
  
---

This code is meant to take output from dada2 and assign taxonomy. This is adapted from Ramon Gallego's "insect.all.Rmd" script found here (https://github.com/ramongallego/eDNA.and.Ocean.Acidification.Gallego.et.al.2020/tree/master/Scripts). 

The general overview is that ASVs from dada2 will be read in, we will find hashes that were already previously annotated from previous runs and pull them out (because we do not need to re-assign taxonomy). We will also take out ASVs that we have already BLASTed by comparing hashes to our local blast database. For ASVs that have not yet been classified (via insect or BLAST), we will start by using the classifier publicly available from the creators of insect (found here - https://cran.r-project.org/web/packages/insect/vignettes/insect-vignette.html). And the FINAL step will be to take the remaining ASVS (not previously classified by insect, not in our BLAST database, and not newly assigned via the insect classifier) and then BLAST them to assign taxonomy and add them to the local blast database. THEN, we will add the newly classified via insect and the newly blasted to the previous efforts, respectively. This is a many step process.
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = params$folder)
```

```{r load libraries, echo = FALSE}
library (tidyverse)
library (insect)
library (seqinr)
library (here)
library(taxonomizr)

run_output_folder <- paste0(here("Output","classification_output"),"/run",params$run) 
dir.create(path = run_output_folder)
run_marker_output_folder <- paste0(run_output_folder,"/",params$marker)
dir.create(path = run_marker_output_folder)

```


## Step 1: Don't reinvent the wheel. Remove ASVs that we previously classified via insect or we have previously BLASTed.

Read in ASV table and hash key for run. Read in previous effort, insect classifier, and previously BLASTed ASVs. Then only work with the leftovers to try to classify or BLAST new things. 

```{r load objects by the end of the cleaning}
Hash     <- read_csv(params$Hash_key) %>% 
  select(Hash, Sequence) %>% distinct()
ALL.ASVs <- read_csv(params$ASVs)

# ### COI -- HAS SOME BACKWARDS
# # #reverse complement the representative sequence for each hash
# cutadapt_metadata <- read.csv("/Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_LOCAL/Output/cutadapt_output/run4_20211117/noprimers/COI/cutadapt_output_metadata_COI.csv")
# is.backwards <- (cutadapt_metadata$rc == 1)
# samples.backwards <- cutadapt_metadata$Sample_name[is.backwards]
# samples.forwards <- cutadapt_metadata$Sample_name[! is.backwards]
# 
# ASVs.fwd <- ALL.ASVs %>%
#   filter(Sample_name %in% samples.forwards)
# ASVs.bkwd <- ALL.ASVs %>%
#   filter(Sample_name %in% samples.backwards)
# 
# Hash.fwds <- Hash %>%
#   filter(Hash %in% ASVs.fwd$Hash)
# Hash.bkwds <- Hash %>%
#   filter(Hash %in% ASVs.bkwd$Hash)
# 
# # actually RC them
# rc_seq <- vector(length = dim(Hash.bkwds)[1])
# # this is ridiculous and shouldn't be for loop but wtf i can't get it to work
# for (i in 1:dim(Hash.bkwds)[1]) {
#   rc_seq[i] = rc(Hash.bkwds[i,2])
# }
# Hash.bkwds$Sequence <- rc_seq
# Hash.bkwds <- Hash.bkwds %>%
#   select(Hash, Sequence) %>% distinct()
# 
# Hash <- rbind(Hash.fwds, Hash.bkwds)

# comment these out if this is the first run and there is no previous effort or blast
previous.effort <- read_rds(params$previous_effort)
previous.blast <- read_rds(params$local_blast)

tree <- read_rds(params$classifier)

```

So these sequences are in the same direction, and they have some shared and some new sequences. 
Let's keep only the unique sequences
Make them into a DNAbin object for insect

```{r make it into a DNA object}
## FOR 12S REMOVE ANYTHING TOO BIG
hash.length <- nchar(Hash$Sequence)
hash.keep <- hash.length < 200
Hash <- Hash[hash.keep,]


## if using a previous effort
new.set <- anti_join(Hash, previous.effort, by = c("Hash" = "representative")) # remove anything previously classified
new.set <- anti_join(new.set, previous.blast, by = c("Hash" = "representative")) # remove anything previously BLASTed
all.hashes.insect <- char2dna(new.set$Sequence)
names (all.hashes.insect) <- new.set$Hash

all.hashes.insect

```

## Step 2: Now classify all the new things with the insect classifier. And then add the new classifications to make a new "previous effort".

Now we only have ASVs that we know nothing about yet.
Let's classify these new sequences in our bin file.

```{r classify}
clasif.hashes <- classify (x = all.hashes.insect, tree = tree, cores = 4)

names(clasif.hashes) <- c('representative', 'taxID', 'taxon', 'rank', 'score', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species')

clasif.hashes %>% 
  unite (family, genus, species, sep = "|", col = "taxa")
clasif.hashes %>% dplyr::count (rank) %>% arrange(desc(n))
```

OK. So now let's save the classification object as an RDS and CSV

```{r save it for now}

clasif.hashes %>% 
  filter(family!= "" & phylum == "") %>% 
  distinct(class) # How many have a valid family but no phylum info
# Add new phylum info
clasif.hashes %>% 
  mutate(phylum = case_when(phylum != "" ~ phylum,
                            TRUE   ~ class))

saveRDS(clasif.hashes, paste0(run_marker_output_folder,"/all.new.hashes.annotated",".rds"))
clasif.hashes <- readRDS(paste0(run_marker_output_folder,"/all.new.hashes.annotated",".rds"))
write.csv(clasif.hashes, paste0(run_marker_output_folder,"/all.new.hashes.annotated",".csv"))

# also write them as a tax table
source(here("functions", "tax.table.R"))
taxtable <- tax.table(clasif.hashes)
write.csv(taxtable,file=paste0(run_marker_output_folder,"/tax.table.csv"))

# but let's only save the "good ones" (genus or species) to use as a previous effort 
species.clasif.hashes <- clasif.hashes %>% filter(rank == "species")
genus.clasif.hashes <- clasif.hashes %>% filter(rank == "genus")
good.clasif.hashes <- rbind(genus.clasif.hashes, species.clasif.hashes)

saveRDS(good.clasif.hashes, file=paste0(run_marker_output_folder,"/gs.new.hashes.annotated.rds"))
good.clasif.hashes <- readRDS(file=paste0(run_marker_output_folder,"/gs.new.hashes.annotated.rds"))
write.csv(good.clasif.hashes, file=paste0(run_marker_output_folder,"/gs.new.hashes.annotated.csv"))

# make and save combined rds file with the previous effort and the new one 
combined <- rbind(previous.effort, all.clasif.hashes)
saveRDS(combined, file=paste0(here("Output","classification_output"),"/", params$marker,".all.previous.hashes.annotated.rds"))

combined.gs <- rbind(previous.effort,good.clasif.hashes)
saveRDS(combined.gs, file=paste0(here("Output","classification_output"),"/", params$marker,".all.gs.previous.hashes.annotated.rds"))
```

## STEP 3: Now we want to take the leftover hashes that were not previously classified, not in our previous local BLAST database, not newly classified -- and we want to BLAST them and add them to make a new local BLAST database. 

```{r prepare leftovers for BLAST}

# keep the things that didn't get classified to then blast later 
not.clasif.hashes <- 
  clasif.hashes %>% 
  filter (taxID == "1")

# ok what if we can get more information on things that don't go to genus or species
bad.clasif.hashes <- 
  clasif.hashes %>% 
  filter (taxID != "1") %>%  # we don't want to reblast what we already are going to blast
  filter(rank != "species") %>% 
  filter(rank != "genus")

hash.to.blast <- Hash %>% 
  filter(Hash %in% not.clasif.hashes$representative) %>% 
  rename(name = Hash) %>% 
  rename(seq = Sequence)

hash.to.blast2 <- Hash %>% 
  filter(Hash %in% bad.clasif.hashes$representative) %>% 
  rename(name = Hash) %>% 
  rename(seq = Sequence)

# turn them into a fasta file to run through BLAST
source(here("functions", "writeFasta.R"))
writeFasta(hash.to.blast, filename=paste0(run_marker_output_folder,"/run", params$run,".",params$marker,".hashes.to.blast.fasta"))
writeFasta(hash.to.blast2, filename=paste0(run_marker_output_folder,"/run", params$run,".",params$marker,".hashes.to.blast2.fasta"))
```

The first step is running this command through the server to blast the results and pull down the data we need for each. SEE GOOGLE DRIVE FOR CODE! (Link: https://drive.google.com/drive/u/1/folders/1Ctgkr0poeogKBv4IJHzzz7q6aVrJLL37)

Then use the 5a.classify.blast.EA.Rmd file to turn the blast results into taxonomy (via LCA) and then we can go back to each run and add the classifications to ASVs that did not get classified on the tree but the BLAST results did have a good (species or genus level) annotation.  

Then we want to add the good classifications from 

```{r add in hashes that were classified with blast}
# blast.bad.rank.results <- readRDS(paste0(run_marker_output_folder,"/blast.badrank.hashes.annotated",".rds"))
# blast.no.rank.hashes <- readRDS(paste0(run_marker_output_folder,"/blast.norank.hashes.annotated",".rds"))
# 
# blast.bad.rank.gs.results <- blast.bad.rank.results %>% 
#   filter(genus != NA)
# 
# blast.no.rank.gs.results <- blast.no.rank.results %>% 
#   filter(genus != NA)
# 
# # this will combine any hash that is given any rank in either the insect tree or the blast results 
# anyrank.insect.plus.blast.clasif.hashes <- x
# 
# # this will combine only hashes that are given a genus or species level rank either via insect or the blast results
# good.insect.plus.blast.clasif.hashes <- x 


```



################################################ GRAVEYARD ################################################ 

```{bash}
#!/bin/bash

BLAST_DB='///_Ev.db'
# BLAST PARAMETERS
PERCENT_IDENTITY="85"
WORD_SIZE="30"
EVALUE="1e-30"
# number of matches recorded in the alignment:
MAXIMUM_MATCHES="50"
CULLING="5"

	################################################################################
	# BLAST CLUSTERS
	################################################################################
	echo $(date +%H:%M) "BLASTing..."
	blast_output="//coi_blast_20210723.txt"
blastn \
		-query "////hash_key.fasta" \
		-db "${BLAST_DB}" \
		-num_threads 4 \
		-perc_identity "${PERCENT_IDENTITY}" \
		-word_size "${WORD_SIZE}" \
		-evalue "${EVALUE}" \
		-max_target_seqs "${MAXIMUM_MATCHES}" \
		-culling_limit="${CULLING}" \
		-outfmt "6 qseqid sseqid sacc pident length mismatch gapopen qcovus qstart qend sstart send evalue bitscore staxids qlen sscinames sseq" \
		-out "${blast_output}"
```



############################################################################################################################################
## IF DESIREABLE - CAN LOOK AT THRESHOLDS - LET'S NOT MAKE IT PART OF THE MAIN SCRIPT BUT DO IT ONCE IN A WHILE

apply thresholds and save modified .rds

```{r apply thresholds}
thresholds <- list(0.8, 0.85, 0.95)
thresholds.classif <- map(thresholds, ~ classify(x= all.hashes.insect,
                                              tree = tree.2,
                                              cores = 8,
                                              threshold = .))
names(thresholds.classif) <- thresholds
#ADD THE DEFAULT
thresholds.classif[[4]] <- clasif.hashes
# Name it
names(thresholds.classif)[4] <- "0.9"
saveRDS(thresholds.classif, file =paste0("hashes.annotated.threshold.rds"))
list.of.thres <- readRDS(file ="hashes.annotated.threshold.rds")
l2 <- lapply (list.of.thres, function (x) as_tibble(x))

```

Check the classification: the resolution of dataset, and classifier, let's see how many reads can be classified to species, genus, family and order level

```{r checking the classification}
clasif.hashes %>% dplyr::count (rank) %>% arrange(desc(n))# an overview of the taxonomic resolution
# a first check: How many sequences did not have a score: Either bc they exactly match a sequence in the tree
clasif.hashes %>% 
  filter (is.na(score)) %>% # 176 Hashes
  left_join(ALL.ASVs, by = c("representative" = "Hash")) %>% 
 # group_by(representative) %>% 
  summarise(tot = sum(nReads)) # 2.7M reads
clasif.hashes %>% 
  filter(rank == "" & !is.na(score)) %>% # 
  left_join(ALL.ASVs, by = c("representative" = "Hash")) %>% 
 # group_by(representative) %>% 
  summarise(tot = sum(nReads)) # 0
 clasif.hashes %>% 
   filter(rank !="") %>% #
   left_join(ALL.ASVs, by = c("representative" = "Hash")) %>% 
 mutate(Sample_name = as.character(Sample_name)) %>%
   group_by(Sample_name) %>% 
  summarise(tot = sum(nReads)) %>% 
   ggplot(aes(x=fct_reorder(Sample_name, tot), y = tot))+
   geom_col()# 
clasif.hashes %>% 
  filter(rank == "")
 
# Create the species- level dataset
map_dfr(l2, ~(dplyr::count(.,rank)), .id = "Threshold" ) -> Summary.thresholds.df# This puts the results in a df


```

summarize by the sum of reads per hash
```{r df of reads per threshold}
  ALL.ASVs %>% group_by(Hash) %>% 
  summarise(n2=sum(nReads)) -> reads.per.hash

map_dfr(l2, ~(dplyr::add_count(.,rank)), .id = "Threshold" ) -> Summary.thresholds.2# This puts the results in a df
```


create plots to visualize the differences in classification bewteen thresholds to see that everything is working
```{r create plots for thresholds}
Summary.thresholds.2 %>% left_join(reads.per.hash, by = c("representative"="Hash")) -> Summary.thresholds.2
Summary.thresholds.2 %>% group_by(Threshold, rank, n) %>% summarise(nReads = sum(n2)) -> Summary.thresholds
unique(Summary.thresholds$rank)
#Summary.thresholds$rank <- fct_relevel(Summary.thresholds.df$rank, "class",   "infraclass", "superorder" , "order" , "suborder", "family", "subfamily" , "tribe",  "genus", "species", "clade", "cohort", "no rank") #this section isn't working to actually re-order the ranks while keeping the reads together
Summary.thresholds %>%
  
  ggplot (aes (x= rank, y = n, fill = Threshold)) +
  geom_col(position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45,vjust = 0.75)) -> p
  
Summary.thresholds %>%
  
  ggplot (aes (x= rank, y = nReads, fill = Threshold)) +
  geom_col(position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45,vjust = 0.75)) -> q
  ggsave(filename = "Different.thresholds.png", width = 14)  
  p+q+plot_layout(guides = "collect")
  ggsave(filename = "Different.thresholds.compare.png", width = 14)
```

