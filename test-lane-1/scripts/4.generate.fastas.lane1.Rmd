---
title: "classify_Leray"
author: "M Fisher - modified from Eily Allan, Erin D'Agnese, Ramon Gallego"
date: "01/06/2022"
output:   
  html_notebook:
    toc: true
    toc_float: true
---


# Description 

This code is meant to take output from dada2 and split the ASVs into forward and reverse reads. This is adapted for PE150 sequencing from Ramon Gallego's "insect.all.Rmd" script found [here](https://github.com/ramongallego/eDNA.and.Ocean.Acidification.Gallego.et.al.2020/tree/master/Scripts). 



# Set up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<br>

This script requires the following R packages
```{r load libraries, echo = FALSE}
library(tidyverse)
library(insect)
library(seqinr)
library(here)
library(taxonomizr)
```
<br>


# Leray

```{r}
params <- data.frame(Hash_key="test-lane-1/data/Leray/hash_key.csv",
                 ASVs="test-lane-1/data/Leray/ASV_table.csv",
                 classifier="data/databases/classifier_COI_Metazoans_Leray_v5_20220106.rds",
                 previous_effort=NA,
                 local_blast=NA,
                 run=1,
                 marker="Leray")
```
<br>

Create the required directories.
```{r}
run_output_folder <- paste0(here("test-lane-1","data","classification_output"),"/run",params$run) 
dir.create(path = run_output_folder)
run_marker_output_folder <- paste0(run_output_folder,"/",params$marker)
dir.create(path = run_marker_output_folder)
```
<br>



## Data

Load Data
```{r}
Hash     <- read_csv(here(params$Hash_key)) %>%
  select(Hash, Sequence) %>% distinct()
ALL.ASVs <- read_csv(here(params$ASVs))
```
<br>

Split data into forward / reverse sequences
```{r}
Hash_split <- Hash %>%
  separate(col=Sequence, sep="NNNNNNNNNN", into=c("forward", "reverse"), remove=TRUE) %>%
  pivot_longer(cols=c("forward","reverse"), names_to="seq_type", values_to="Sequence") %>%
  mutate(Hash=ifelse(seq_type=="forward",paste0(Hash,"fff"), paste0(Hash,"rrr")))
```
<br>

```{r}
split.hashes.insect <- char2dna(Hash_split$Sequence)
names (split.hashes.insect) <- Hash_split$Hash

split.hashes.insect
```
<br>

## Create FASTA
```{r prepare leftovers for BLAST}
hash.to.blast <- Hash_split %>% 
  rename(name = Hash) %>% 
  rename(seq = Sequence)

# turn them into a fasta file to run through BLAST
source(here("R", "writeFasta.R"))
writeFasta(hash.to.blast, filename=here("test-lane-1","data","Leray","hash_split_key.fasta"))
```
<br>
<br>



# LerayXT


```{r}
params <- data.frame(Hash_key="test-lane-1/data/LerayXT/hash_key.csv",
                 ASVs="test-lane-1/data/LerayXT/ASV_table.csv",
                 run=1,
                 marker="LerayXT")
```
<br>


## Data

Load Data
```{r}
Hash     <- read_csv(here(params$Hash_key)) %>%
  select(Hash, Sequence) %>% distinct()
ALL.ASVs <- read_csv(here(params$ASVs))
```
<br>

Split data into forward / reverse sequences
```{r}
Hash_split <- Hash %>%
  separate(col=Sequence, sep="NNNNNNNNNN", into=c("forward", "reverse"), remove=TRUE) %>%
  pivot_longer(cols=c("forward","reverse"), names_to="seq_type", values_to="Sequence") %>%
  mutate(Hash=ifelse(seq_type=="forward",paste0(Hash,"fff"), paste0(Hash,"rrr")))
```
<br>

Use `insect` to convert DNA and amino acid sequences
```{r}
all.hashes.insect <- char2dna(Hash$Sequence)
names (all.hashes.insect) <- Hash$Hash

all.hashes.insect
```
<br>

```{r}
split.hashes.insect <- char2dna(Hash_split$Sequence)
names (split.hashes.insect) <- Hash_split$Hash

split.hashes.insect
```
<br>


## Create FASTA
```{r}
hash.to.blast <- Hash_split %>% 
  rename(name = Hash) %>% 
  rename(seq = Sequence)

# turn them into a fasta file to run through BLAST
source(here("R", "writeFasta.R"))
writeFasta(hash.to.blast, filename=here("test-lane-1","data","LerayXT","hash_split_key.fasta"))
```
<br>
<br>

# BF3

```{r}
params <- data.frame(Hash_key="test-lane-1/data/BF3/hash_key.csv",
                 ASVs="test-lane-1/data/BF3/ASV_table.csv",
                 run=1,
                 marker="BF3")
```
<br>


## Data

Load Data
```{r}
Hash     <- read_csv(here(params$Hash_key)) %>%
  select(Hash, Sequence) %>% distinct()
ALL.ASVs <- read_csv(here(params$ASVs))
```
<br>

Split data into forward / reverse sequences
```{r}
Hash_split <- Hash %>%
  separate(col=Sequence, sep="NNNNNNNNNN", into=c("forward", "reverse"), remove=TRUE) %>%
  pivot_longer(cols=c("forward","reverse"), names_to="seq_type", values_to="Sequence") %>%
  mutate(Hash=ifelse(seq_type=="forward",paste0(Hash,"fff"), paste0(Hash,"rrr")))
```
<br>

Use `insect` to convert DNA and amino acid sequences
```{r}
all.hashes.insect <- char2dna(Hash$Sequence)
names (all.hashes.insect) <- Hash$Hash

all.hashes.insect
```
<br>

```{r}
split.hashes.insect <- char2dna(Hash_split$Sequence)
names (split.hashes.insect) <- Hash_split$Hash

split.hashes.insect
```
<br>


## Create FASTA
```{r}
hash.to.blast <- Hash_split %>% 
  rename(name = Hash) %>% 
  rename(seq = Sequence)

# turn them into a fasta file to run through BLAST
source(here("R", "writeFasta.R"))
writeFasta(hash.to.blast, filename=here("test-lane-1","data",params$marker,"hash_split_key.fasta"))
```
<br>
<br>


# Next Steps

The next step is comparing the fasta files to the NCBI's nucleotide database. 

Update the blast database
```{bash eval=FALSE}
./update_blastdb.pl --decompress nt
```
<br>

Use a shell script to compare each marker's fasta files to the database. 
```{bash eval=FALSE}
#!/bin/bash

PATH=$PATH:"~/Documents/Mary/ncbi-blast-2.12.0+/bin"
export BLASTDB="~/Documents/Mary/blastdb"

BLAST_DB='~/Documents/Mary/blastdb/nt'
# BLAST PARAMETERS
PERCENT_IDENTITY="85"
WORD_SIZE="30"
EVALUE="1e-30"
# number of matches recorded in the alignment:
MAXIMUM_MATCHES="50"
CULLING="5"

	################################################################################
	# BLAST CLUSTERS
	################################################################################
	echo $(date +%H:%M) "BLASTing..."

	blast_output="~/Documents/Mary/data/BF3.run1.blast.txt" 
	blastn \
		-query "~/Documents/Mary/data/BF3/hash_key.fasta" \
		-db "${BLAST_DB}" \
		-num_threads 16 \
		-perc_identity "${PERCENT_IDENTITY}" \
		-word_size "${WORD_SIZE}" \
		-evalue "${EVALUE}" \
		-max_target_seqs "${MAXIMUM_MATCHES}" \
		-culling_limit="${CULLING}" \
		-outfmt "6 qseqid sseqid sacc pident length mismatch gapopen qcovus qstart qend sstart send evalue bitscore staxids qlen sscinames sseq" \
		-out "${blast_output}"


	echo $(date +%H:%M) "BLASTing second batch..."

	blast_output="~/Documents/Mary/data/BF3.run1.split.blast.txt" 
	blastn \
		-query "~/Documents/Mary/data/BF3/hash_split_key.fasta" \
		-db "${BLAST_DB}" \
		-num_threads 16 \
		-perc_identity "${PERCENT_IDENTITY}" \
		-word_size "${WORD_SIZE}" \
		-evalue "${EVALUE}" \
		-max_target_seqs "${MAXIMUM_MATCHES}" \
		-culling_limit="${CULLING}" \
		-outfmt "6 qseqid sseqid sacc pident length mismatch gapopen qcovus qstart qend sstart send evalue bitscore staxids qlen sscinames sseq" \
		-out "${blast_output}"

```
<br>





running this command through the server to blast the results and pull down the data we need for each. SEE GOOGLE DRIVE FOR CODE! (Link: https://drive.google.com/drive/u/1/folders/1Ctgkr0poeogKBv4IJHzzz7q6aVrJLL37)

Then use the 5a.classify.blast.EA.Rmd file to turn the blast results into taxonomy (via LCA) and then we can go back to each run and add the classifications to ASVs that did not get classified on the tree but the BLAST results did have a good (species or genus level) annotation.  
